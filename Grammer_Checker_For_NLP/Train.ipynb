{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammer Checker for Natural language text: A syntactically processing approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. *Data Collection and Annotation*:\n",
    "   - Gather a large dataset of natural language text with annotated grammatical errors. Annotate each error type (e.g., subject-verb agreement, tense inconsistency) to create a labeled dataset for training your ML models.\n",
    "\n",
    "2. *Feature Extraction*:\n",
    "   - Extract features from the input text that are relevant to grammatical error detection and correction. These features may include syntactic features derived from parsed trees/graphs, lexical features, contextual features, and error-specific features.\n",
    "\n",
    "3. *Model Selection*:\n",
    "   - Choose appropriate ML models for error detection and correction tasks. Common models include:\n",
    "     - *Sequence Models*: Models like recurrent neural networks (RNNs) or long short-term memory (LSTM) networks can be used for sequence labeling tasks, such as part-of-speech tagging or named entity recognition.\n",
    "     - *Transformer Models*: Transformer-based architectures like BERT (Bidirectional Encoder Representations from Transformers) or GPT (Generative Pre-trained Transformer) can capture contextual information effectively and are suitable for a wide range of NLP tasks.\n",
    "     - *Conditional Random Fields (CRFs)*: CRFs are often used for sequence labeling tasks, where the output depends on the entire input sequence.\n",
    "\n",
    "4. *Training*:\n",
    "   - Train your ML models using the annotated dataset. Fine-tune pre-trained models on your specific task to improve performance and adapt them to the grammatical error detection and correction domain.\n",
    "\n",
    "5. *Evaluation*:\n",
    "   - Evaluate the performance of your ML models on a separate evaluation dataset. Use standard evaluation metrics such as precision, recall, and F1-score to measure the accuracy of error detection and correction.\n",
    "\n",
    "6. *Integration with Syntactic Processing*:\n",
    "   - Integrate ML-based models with syntactic processing techniques to leverage the strengths of both approaches. For example, use syntactic parsing to provide structural information to ML models or combine syntactic features with learned representations for better error detection and correction.\n",
    "\n",
    "7. *User Interface*:\n",
    "   - Design a user-friendly interface that interacts with your ML models to input text, display detected errors, and suggest corrections. Provide options for users to accept or reject corrections and provide feedback to improve the system.\n",
    "\n",
    "8. *Documentation and Deployment*:\n",
    "   - Document the ML models used, training procedures, and integration with other components of the grammar checker. Deploy the grammar checker with ML models as a standalone tool or integrate it into existing applications or platforms.\n",
    "\n",
    "By leveraging ML models as a major part of your grammar checker project, you can achieve higher accuracy and robustness in detecting and correcting grammatical errors in natural language text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for Grammar Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for Grammar Checker\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('path_to_your_model')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = load_tokenizer('path_to_your_tokenizer')\n",
    "\n",
    "def grammar_checker(input_text):\n",
    "    # Tokenize the input text\n",
    "    tokenized_text = tokenizer.tokenize(input_text)\n",
    "    \n",
    "    # Predict the error locations and types using the model\n",
    "    error_predictions = model.predict(tokenized_text)\n",
    "    \n",
    "    # For each predicted error in the text\n",
    "    for error in error_predictions:\n",
    "        # Identify the error type and location\n",
    "        error_type, error_location = identify_error(error)\n",
    "        \n",
    "        # Generate correction for the error\n",
    "        correction = generate_correction(error_type, error_location, tokenized_text)\n",
    "        \n",
    "        # Replace the error in the text with the correction\n",
    "        tokenized_text = replace_error_with_correction(tokenized_text, error_location, correction)\n",
    "    \n",
    "    # Detokenize the text\n",
    "    corrected_text = tokenizer.detokenize(tokenized_text)\n",
    "    \n",
    "    return corrected_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for Grammar Checker using Gramformer\n",
    "\n",
    "# Import the necessary libraries\n",
    "from gramformer import Gramformer\n",
    "\n",
    "# Initialize the Gramformer model\n",
    "gf = Gramformer(models=1)  # 0=detector, 1=highlighter, 2=corrector, 3=all \n",
    "\n",
    "def grammar_checker(input_text):\n",
    "    # Use the Gramformer model to correct the input text\n",
    "    corrections = gf.correct(input_text)\n",
    "    \n",
    "    # The 'correct' method returns a list of corrections. \n",
    "    # If multiple corrections are possible, it will return all of them.\n",
    "    # Here, we're just taking the first one.\n",
    "    corrected_text = corrections[0]\n",
    "    \n",
    "    return corrected_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "Gramformer is a framework for detecting, highlighting, and correcting grammatical errors in natural language text¹. It was created by Prithiviraj Damodaran and is open to collaboration¹. Gramformer exposes three separate interfaces to a family of algorithms to detect, highlight, and correct grammar errors¹.\n",
    "\n",
    "**Methodology**\n",
    "Gramformer leverages state-of-the-art NLP Transformer models like T5². It works at the sentence level and has been trained on sentences of length 64¹. It combines some of the top-notch research in grammar correction¹. However, it's important to note that the fine-tuning for this model is done on relatively smaller models with not-so-much data due to compute budget constraints¹.\n",
    "\n",
    "**Applications**\n",
    "Gramformer has potential applications in several areas:\n",
    "1. **Post-processing machine-generated text**: Machine-Language generation is becoming mainstream, so will post-processing machine-generated text¹.\n",
    "2. **Human-In-The-Loop (HITL) text**: Most Supervised NLU (Chatbots and Conversational) systems need humans/experts to enter or edit text that needs to be grammatically correct¹.\n",
    "3. **Assisted writing for humans**: Integrating into custom Text editors of your Apps¹.\n",
    "4. **Custom Platform integration**: As of today, grammatical safety nets for authoring social contents (Post or Comments) or text in messaging platforms is very little (word level correction) or non-existent¹.\n",
    "\n",
    "**Limitations**\n",
    "While Gramformer is a powerful tool, it does have some limitations. It works at sentence levels and has been trained on 64 length sentences, so it's not (yet) suitable for long prose or paragraphs¹. Also, the results should be taken with a pinch of salt and considered as a proof-of-concept for a novel method for generating grammar error correction dataset¹.\n",
    "\n",
    "**Future Work**\n",
    "The creator of Gramformer is working on a version based on a larger base model and a lot more data for those who might want to use this in a production setup¹.\n",
    "\n",
    "**Conclusion**\n",
    "In conclusion, Gramformer is a promising tool for grammar correction. It combines the power of transformer models with the flexibility of Python, making it a valuable resource for anyone looking to improve the grammatical accuracy of their text².\n",
    "\n",
    "(1) https://github.com/PrithivirajDamodaran/Gramformer.\n",
    "(2) https://www.vennify.ai/gramformer-correct-grammar-transformer-nlp/.\n",
    "(3) https://github.com/PrithivirajDamodaran/Gramformer.git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/PrithivirajDamodaran/Gramformer.git\n",
    "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
    "!pip install --upgrade gramformer\n",
    "!pip install transformers\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baldo\\anaconda3\\envs\\python3.8\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baldo\\anaconda3\\envs\\python3.8\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:711: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\baldo\\anaconda3\\envs\\python3.8\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "Highlighter model loaded successfully.\n",
      "TO BE IMPLEMENTED!!!\n",
      "Corrector model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "\n",
    "# Try loading individual models\n",
    "try:\n",
    "    gf_detector = Gramformer(models=0, use_gpu=False)  # Detector model\n",
    "    print(\"Detector model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading detector model:\", e)\n",
    "\n",
    "try:\n",
    "    gf_highlighter = Gramformer(models=1, use_gpu=False)  # Highlighter model\n",
    "    print(\"Highlighter model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading highlighter model:\", e)\n",
    "\n",
    "try:\n",
    "    gf_corrector = Gramformer(models=2, use_gpu=False)  # Corrector model\n",
    "    print(\"Corrector model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading corrector model:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "Highlighted Sentence: {'My camera battery is dead.'}\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "\n",
    "# Load Gramformer with only detector and highlighter models\n",
    "gf = Gramformer(models=1, use_gpu=False)  # Detector and Highlighter models only\n",
    "\n",
    "# Detect and highlight grammar errors\n",
    "highlighted_sentence = gf.correct('My camera battery a dead')\n",
    "\n",
    "print(\"Highlighted Sentence:\", highlighted_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Gramformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "gf = Gramformer(models=1, use_gpu=True) # 0 = detector, 1 = highlighter, 2 = corrector, 3 = all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'My camera battery is dead.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.correct('My camera battery a dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'I like for walks', \n",
    "    'World is flat', \n",
    "    'Red a color', \n",
    "    'I wish my Computer was run faster.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I like walks.'}\n",
      "{'The world is flat.'}\n",
      "{'Red a color'}\n",
      "{'I wish my computer was running faster.'}\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    res = gf.correct(sentence)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together with Gradio\n",
    "\n",
    "Gradio is an open-source Python library that allows you to quickly create customizable user interfaces for your machine learning models, APIs, or any arbitrary Python function¹²³⁴. It's designed to work with a wide range of machine learning frameworks, including TensorFlow, PyTorch, and scikit-learn³.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. **Function Wrapping**: You wrap your function, machine learning model, or API with Gradio's `Interface` class¹². This class takes three core arguments: the function to wrap (`fn`), the input components (`inputs`), and the output components (`outputs`)².\n",
    "\n",
    "2. **Interface Creation**: You create an interface using the `gradio.Interface()` function¹. This function takes in your function, the input components, and the output components as parameters¹.\n",
    "\n",
    "3. **Launching the Interface**: You launch the interface using the `launch()` method¹. This method can take a `share` parameter, which, if set to `True`, creates a publicly shareable link from your computer for the interface¹.\n",
    "\n",
    "4. **Interacting with the Interface**: Once the interface is launched, you can interact with it directly in your Python notebook, or anyone can interact with it via the shared link¹².\n",
    "\n",
    "5. **Hot Reloading**: When developing locally, you can run your Gradio app in hot reload mode, which automatically reloads the Gradio app whenever you make changes to the file².\n",
    "\n",
    "Gradio requires no knowledge of HTML, CSS, or JavaScript, making it a great tool for quickly prototyping and sharing machine learning models and other functions¹²³⁴.\n",
    "\n",
    "(1) https://www.geeksforgeeks.org/python-create-uis-for-prototyping-machine-learning-model-with-gradio/.\n",
    "(2) https://www.gradio.app/guides/quickstart.\n",
    "(3) https://medium.com/@HeCanThink/gradio-the-new-frontier-in-interactive-python-data-apps-64b5ce06628a.\n",
    "(4) https://www.machinelearningnuggets.com/gradio-tutorial/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(sentence):\n",
    "    res = gf.correct(sentence) # Gramformer correct\n",
    "    return res # Return first value in res array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_inputs = gr.Textbox(lines=2, placeholder=\"Enter sentence here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=correct, \n",
    "                        inputs=app_inputs,\n",
    "                         outputs='text', \n",
    "                        title='Sup, I\\'m Gramformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
